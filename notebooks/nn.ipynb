{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_feather(\"../data/filtered_dataset.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset['sequence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from typing import List\n",
    "\n",
    "class LinearClassificationModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearClassificationModule, self).__init__()\n",
    "        self.net = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TwoLayerClassificationModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerClassificationModule, self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, hidden_size),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class IdentityDNAFeatureTransformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityDNAFeatureTransformer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, base_model=\"zhihan1996/DNABERT-S\", dna_feature_transformer=None, classification_module=None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.dna_tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "        self.dna_encoder_model = AutoModel.from_pretrained(base_model, trust_remote_code=True)\n",
    "\n",
    "        if dna_feature_transformer is not None:\n",
    "            self.dna_feature_transformer = dna_feature_transformer\n",
    "        else:\n",
    "            self.dna_feature_transformer = IdentityDNAFeatureTransformer()\n",
    "\n",
    "        if classification_module is None:\n",
    "            raise ValueError(\"classification_module must be provided! \")\n",
    "\n",
    "        self.classification_module = classification_module\n",
    "\n",
    "    def encode_dna(self, dna_sequences: List[str]):\n",
    "        inputs = self.dna_tokenizer(dna_sequences, return_tensors=\"pt\", padding=True)\n",
    "        outputs = self.dna_encoder_model(**inputs)\n",
    "        embeddings = outputs[0].mean(dim=1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "    def forward(self, sequences):\n",
    "\n",
    "        embeddings = self.encode_dna(sequences)\n",
    "        transformed_embeddings = self.dna_feature_transformer(embeddings)\n",
    "        predictions = self.classification_module(transformed_embeddings)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/rfeng44/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-S/1cdf84d992ace6f3e75c7356774b4da088c8dc7c/bert_layers.py:125: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cls_module = LinearClassificationModule(768, 4)\n",
    "two_layer_cls_module = TwoLayerClassificationModule(768, 256, 4)\n",
    "net = Net(classification_module=two_layer_cls_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0404, -0.0223, -0.0001,  0.0614],\n",
       "        [ 0.0256, -0.0333,  0.0324,  0.0752],\n",
       "        [ 0.0402, -0.0365,  0.0054,  0.0722],\n",
       "        [ 0.0440, -0.0327,  0.0202,  0.0353],\n",
       "        [ 0.0515, -0.0527,  0.0188,  0.0783],\n",
       "        [ 0.0470, -0.0433,  0.0090,  0.0420],\n",
       "        [ 0.0185, -0.0294,  0.0264,  0.0587],\n",
       "        [ 0.0360, -0.0324,  0.0335,  0.0836],\n",
       "        [ 0.0328, -0.0277,  0.0102,  0.0621],\n",
       "        [ 0.0632, -0.0174,  0.0143,  0.0607]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(inputs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
